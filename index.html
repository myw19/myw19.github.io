<!doctype html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Homepage of Mengyue Wu</title>
<link href="AboutPageAssets/styles/aboutPageStyle.css" rel="stylesheet" type="text/css">

<!--The following script tag downloads a font from the Adobe Edge Web Fonts server for use within the web page. We recommend that you do not modify it.-->
<script>var __adobewebfontsappname__="dreamweaver"</script><script src="http://use.edgefonts.net/montserrat:n4:default;source-sans-pro:n2:default.js" type="text/javascript"></script>
</head>

<body>
<!-- Header content -->
<header>
  <div class="profileLogo"> 
    <!-- Profile logo. Add a img tag in place of <span>. -->
    <p class="logoPlaceholder"><!-- <img src="logoImage.png" alt="sample logo"> --><span>LOGO</span></p>
  </div>
  <div class="profilePhoto"> 
    <!-- Profile photo --> 
    <img src="AboutPageAssets/images/profilephoto.png" alt="sample"> </div>
  <!-- Identity details -->
  <section class="profileHeader">
    <h1>Mengyue WU 吴梦玥</h1>
    <h3>A Scholar, a Researcher and an Explorer!</h3>
    <hr>
    <p>Hi hi! This is Mengyue 梦玥, interested in everything about human speech and perception/production. Specifically, my current research mainly lies on **Rich Audio Analysis**, though I always reckon this is an invented term. It does not have a definition per se, however I refer it to everything in audio processing excluding speech recognition. I'd like to stick to it - my very first student (co-supervised PhD, Heinrich) at SJTU has a funny username "richman" and my very first learned French sentence is "Je suis riche" (pls blame Duolingo for boosting our ego)! Due to work requirements (probably only existing in my head), I'll present a very official biography below. However just feel free to drop me a line if you share any similar interests/curiosity towards audio/acoustics/language/psychology/psychiatry/neuroscience etc. Have a chat - should be fun (not guaranteed on your side)!</p>
  </section>
  <!-- Links to Social network accounts -->
  <aside class="socialNetworkNavBar">
    <div class="socialNetworkNav"> 
      <!-- Add a Anchor tag with nested img tag here --> 
      <img src="AboutPageAssets/images/social.png" alt="sample"> </div>
    <div class="socialNetworkNav"> 
      <!-- Add a Anchor tag with nested img tag here --> 
      <img src="AboutPageAssets/images/social.png"  alt="sample"> </div>
    <div class="socialNetworkNav"> 
      <!-- Add a Anchor tag with nested img tag here --> 
      <img src="AboutPageAssets/images/social.png"  alt="sample"> </div>
    <div class="socialNetworkNav"> 
      <!-- Add a Anchor tag with nested img tag here --> 
      <img src="AboutPageAssets/images/social.png"  alt="sample"> </div>
  </aside>
</header>
<!-- content -->
<section class="mainContent"> 
  <section class="section1">
    <h2 class="sectionTitle">basic information&nbsp;</h2>
    <hr class="sectionTitleRule">
    <hr class="sectionTitleRule2">
    <div class="section1Content">
	  <p>Associate Professor</p>
	  <a href="https://x-lance.sjtu.edu.cn/">X-LANCE LAB</a><br/><br/>
	  <a href="https://www.cs.sjtu.edu.cn/">Department of Computer Science and Engineering</a>
	  <p>Shanghai Jiao Tong University</p>
      <p><span>Address :</span> 3-225 SEIEE Building, 800 Dongchuan Road, Shanghai 200240, China</p>
      <p><span>Email :</span> mengyuewu@sjtu.edu.cn</p>
      <p><span>Website :</span> myw19.github.io</p>
      <p>&nbsp;</p>
    </div>
  </section>
  <section class="section2">
    <h2 class="sectionTitle">Education</h2>
    <hr class="sectionTitleRule">
    <hr class="sectionTitleRule2">
    <!-- First Title & company details  -->
    <article class="section2Content">
		<p class="sectionContent"> Ph.D. degree, the Phonetics Lab, University of Melbourne, 2017</p>
		<p class="sectionContent"> B.Sc/B.A., Beijing Normal University, 2011  </p>
    </article>

    <!-- Replicate the above Div block to add more title and company details --> 
  </section>
	<section class="section2">
    <h2 class="sectionTitle">Work Experience</h2>
    <hr class="sectionTitleRule">
    <hr class="sectionTitleRule2">
    <!-- First Title & company details  -->
    <article class="section2Content">
	  <p class="sectionContent"> Associate Professor, Department of Computer Science and Engineering, Shanghai Jiao Tong University, 2018-present </p>
	  <p class="sectionContent"> Visiting scholar, MARCS Institute for Brain, Behaviour &amp; Development, 2014-2018</p>
    </article>
    <!-- Replicate the above Div block to add more title and company details --> 
  </section>
	<section class="section2">
    <h2 class="sectionTitle">Teaching</h2>
    <hr class="sectionTitleRule">
    <hr class="sectionTitleRule2">
    <!-- First Title & company details  -->
    <article class="section2Content">
	  <p class="sectionContent"> Class Course </p>
    </article>
    <!-- Replicate the above Div block to add more title and company details --> 
  </section>	
	<section class="section2">
    <h2 class="sectionTitle">Research Interests</h2>
    <hr class="sectionTitleRule">
    <hr class="sectionTitleRule2">
    <!-- First Title & company details  -->
	<article class="section2Content">
		<p class="sectionContent">SJTU X-LANCE Lab 上海交通大学跨媒体语言智能实验室丰富音频研究组</p>
		<p class="sectionContent"><strong>Environment Sound:</strong></p>
		<ul class="sectionContent">
		<li>Sound event and scene detection</li>
		<li>Audio caption, bridging the gap between audio analysis and natural language description</li>
		<li>Audio-visual event detection</li>
		</ul>
		<p class="sectionContent"><strong>Human Speech: medical application</strong> </p>
		<ul class="sectionContent">
		<li>Speech emotion analysis</li>
		<li>Depression&#x2F;parkinson’s&#x2F;Alzheimer’s disease detection</li>
		<li>Acoustic-based disease diagnosis, e.g. coughing, voice, heartsound…</li>
		</ul>
	</article>
    <!-- Replicate the above Div block to add more title and company details --> 
  </section>
	<section class="section2">
    <h2 class="sectionTitle">Professional Activities</h2>
    <hr class="sectionTitleRule">
    <hr class="sectionTitleRule2">
    <!-- First Title & company details  -->
    <article class="section2Content">
	  <p class="sectionContent"> <strong>Fellow</strong>, 123</p>
	  <p class="sectionContent"> <strong>Member</strong>, 123</p>
    </article>
    <!-- Replicate the above Div block to add more title and company details --> 
  </section>
	<section class="section2">
    <h2 class="sectionTitle">Publications</h2>
    <hr class="sectionTitleRule3">
	<p class="sectionContent"><strong>Selected Journal Papers</strong></p>
	<ol class="sectionContent">
	<li>Heinrich Dinkel, Shuai Wang, Xuenan Xu, <strong>Mengyue Wu</strong> and Kai Yu. Voice activity detection in the wild: A data-driven approach using teacher-student training. IEEE&#x2F;ACM Transactions on Audio, Speech, and Language Processing, vol. 29, pp. 1542-1555, 2021.</li>
	<li>Heinrich Dinkel, <strong>Mengyue Wu</strong> and Kai Yu. Towards Duration Robust Weakly Supervised Sound Event Detection. IEEE&#x2F;ACM Transactions on Audio, Speech, and Language Processing, vol. 29, pp. 887-900, 2021.</li>
	</ol>
	<p class="sectionContent"><strong>Selected Conference Papers</strong></p>
	<ol class="sectionContent">
	<li>Pingyue Zhang, <strong>Mengyue Wu</strong>, Heinrich Dinkel and Kai Yu. DEPA: Self-Supervised Audio Embedding for Depression Detection. In Proceedings of the 29th ACM International Conference on Multimedia (ACM-MM), Virtual Event, China, 2021, 135-143.</li>
	<li>Zhiling Zhang, Zelin Zhou, Haifeng Tang, Guangwei Li, <strong>Mengyue Wu</strong> and Kenny Q. Zhu. Enriching Ontology with Temporal Commonsense for Low-Resource Audio Tagging. In Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management (CIKM), Queensland, Australia, 2021, 3652-3656.</li>
	<li>Xuenan Xu, Heinrich Dinkel, <strong>Mengyue Wu</strong> and Kai Yu. A Lightweight Framework for Online Voice Activity Detection in the Wild. Proc. Interspeech 2021, 371-375, doi: 10.21437&#x2F;Interspeech.2021-1977.</li>
	<li>Zhi Chen, Lu Chen, Hanqi Li, Ruisheng Cao, Da Ma, <strong>Mengyue Wu</strong> and Kai Yu. Decoupled Dialogue Modeling and Semantic Parsing for Multi-Turn Text-to-SQL. Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 3063–3074, August 1–6, 2021.</li>
	<li>Xuenan Xu, Heinrich Dinkel, <strong>Mengyue Wu</strong>, Zeyu Xie and Kai Yu. Investigating Local and Global Information for Automated Audio Captioning with Transfer Learning. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Toronto, Ontario, Canada, 2021, 905-909.</li>
	<li>Xuenan Xu, Heinrich Dinkel, <strong>Mengyue Wu</strong> and Kai Yu. Text-to-Audio Grounding: Building Correspondence Between Captions and Sound Events. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Toronto, Ontario, Canada, 2021, 606-610.</li>
	<li>Xuenan Xu, Heinrich Dinkel, <strong>Mengyue Wu</strong> and Kai Yu. Audio Caption in a Car Setting with a Sentence-Level Loss. In The 12th International Symposium on Chinese Spoken Language Processing (ISCSLP), Hong Kong, China, 2021, 1-5.</li>
	<li>Yefei Chen, Heinrich Dinkel, <strong>Mengyue Wu</strong> and Kai Yu. Voice activity detection in the wild via weakly supervised sound event detection. In 21st Annual Conference of the International Speech Communication Association (InterSpeech), Shanghai, China, 2020, 3665-3669.</li>
	<li>Xuenan Xu, Heinrich Dinkel, <strong>Mengyue Wu</strong> and Kai Yu. A CRNN-GRU Based Reinforcement Learning Approach to Audio Captioning. In The 5th Workshop on Detection and Classification of Acoustic Scenes and Events (DCASE), Tokyo, Japan, 2020, 225-229.</li>
	<li>Rui Qian, Di Hu, Heinrich Dinkel, <strong>Mengyue Wu</strong>, Ning Xu and Weiyao Lin. Multiple Sound Sources Localization from Coarse to Fine. The European Conference on Computer Vision (ECCV), Glasgow, 2020.</li>
	<li>Rui Qian, Di Hu, Heinrich Dinkel, <strong>Mengyue Wu</strong>, Ning Xu and Weiyao Lin. A Two-Stage Framework for Multiple Sound-Source Localization. CVPR Sight and Sound Workshop, 2020.</li>
	<li><strong>Mengyue Wu</strong>, Heinrich Dinkel and Kai Yu. Audio Caption: Listen and Tell. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Brighton, UK, 2019, 830-834.</li>
	</ol>
  </section>
	
  <!-- Links to expore your past projects and download your hp -->
  <aside class="externalResourcesNav">
    <div class="externalResources"> <a href="#" title="Download homepage Link">DOWNLOAD</a> </div>
    <span class="stretch"></span>
    <div class="externalResources"><a href="#" title="Linked-in Link">Linked-in</a> </div>
    <span class="stretch"></span>
    <div class="externalResources"><a href="#" title="https://github.com/myw19">GITHUB</a> </div>
  </aside>
</section>
<footer>
  <hr>
  <p class="footerDisclaimer">2022  Copyrights - <span>All Rights Reserved</span></p>
  <p class="footerNote">Mengyue Wu - <span>Email me</span></p>
</footer>
</body>
</html>
