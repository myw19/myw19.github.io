<!doctype html>
<html><head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Homepage of Mengyue Wu</title>
<link href="AboutPageAssets/styles/aboutPageStyle.css" rel="stylesheet" type="text/css">

<!--The following script tag downloads a font from the Adobe Edge Web Fonts server for use within the web page. We recommend that you do not modify it.-->
<script>var __adobewebfontsappname__="dreamweaver"</script><script src="http://use.edgefonts.net/montserrat:n4:default;source-sans-pro:n2:default.js" type="text/javascript"></script>
</head>

<body>
<!-- Header content -->
<header>
  <div class="profileLogo"> 
    <!-- Profile logo. Add a img tag in place of <span>. -->
    <img src="AboutPageAssets/images/x_lance.png" alt="sample" height="149" width="500"> </div>
  <div class="profilePhoto"> 
    <!-- Profile photo --> 
    <img src="AboutPageAssets/images/profile.png" alt="sample" height="259" width="259"> </div>
  <!-- Identity details -->
  <section class="profileHeader">
    <h1>Mengyue WU 吴梦玥</h1>
    <h3>Digital Mental Health and Auditory Analysis</h3>
    <hr>
    <p>Hi hi! This is Mengyue 梦玥 [IPA：[məŋ4 y̯ɛ4], both high falling tones], interested in everything about human speech and perception/production. Specifically, my current research mainly lies on <strong>Rich Audio Analysis</strong>, though I always reckon this is an invented term. It does not have a definition per se, however I refer it to everything in audio processing excluding speech recognition. I'd like to stick to it - my very first student (co-supervised PhD, Heinrich) at SJTU has a funny username "richman" and my very first learned French sentence is "Je suis riche" (pls blame Duolingo for boosting our ego)!<br>
	    <br>Due to work requirements (probably only existing in my head), I'll present a very official biography below. <br>
	    However just feel free to drop me a line if you share any similar interests/curiosity towards audio/acoustics/language/psychology/psychiatry/neuroscience etc.<br> 
	    Have a chat - should be fun (not guaranteed on your side)!</p>
  </section>
</header>
<!-- content -->
<section class="mainContent"> 
  <section class="section1">
    <h2 class="sectionTitle">basic information&nbsp;</h2>
    <hr class="sectionTitleRule">
    <hr class="sectionTitleRule2">
    <div class="section1Content">
	  <p>Associate Professor, PhD Supervisor</p>
	  <a href="https://x-lance.sjtu.edu.cn/">X-LANCE LAB</a><br/><br/>
	  <a href="https://www.cs.sjtu.edu.cn/">Department of Computer Science and Engineering</a>
	  <p>Shanghai Jiao Tong University</p>
      <p><span>Address :</span> 3-543 SEIEE Building, 800 Dongchuan Road, Shanghai 200240, China</p>
      <p><span>Email :</span> mengyuewu@sjtu.edu.cn</p>
      <p>&nbsp;</p>
    </div>
  </section>

    <!-- Replicate the above Div block to add more title and company details --> 
  </section>	
	<section class="section2">
    <h2 class="sectionTitle">Research</h2>
    <hr class="sectionTitleRule">
    <hr class="sectionTitleRule2">
    <!-- First Title & company details  -->
	<article class="section2Content">
		<p class="sectionContent">SJTU X-LANCE Lab 上海交通大学跨媒体语言智能实验室丰富音频研究组</p>
		<p class="sectionContent"><strong>Environment Sound:</strong></p>
		<ul class="sectionContent">
		<li>Sound event and scene detection, <strong>generation</strong> (!almost every student interested in genreation now..)</li>
		<li>Audio caption, bridging the gap between audio analysis and natural language description</li>
		<li>Audio-visual event detection</li>
		<li><strong>Animal language</strong> decoding, now puppy language, in expansion</li>
		</ul>
		<p class="sectionContent"><strong>Human Speech: medical application</strong> </p>
		<ul class="sectionContent">
		<li>Speech emotion analysis</li>
		<li>Depression&#x2F;Parkinson’s&#x2F;Alzheimer’s disease detection</li>
		<li>Acoustic-based disease diagnosis, e.g. coughing, voice, heartsound…</li>
		</ul>
		<p class="sectionContent"><strong>Digital Mental Health: Text and Dialogue</strong> </p>
		<ul class="sectionContent">
		<li>LLM for mental health</li>
		<li>Social media based disease detection and causal mining</li>
	        <li>Dialogue based depression/anxiety diagnosis and therapy - building psychiatrist and therapist bots! Fun!</li>
		</ul>
		<p class="sectionContent"><strong>Open-Sourced Data and Models</strong> </p>
		<ul class="sectionContent">
		<li><a href="https://arxiv.org/abs/2402.18409">CogBench</a>: A Cognitive Evaluation Benchmark of Image Reasoning and Description for LLM</li>
		<li><a href="https://aclanthology.org/2022.emnlp-main.677.pdf">PsySym</a>: An Interpretable Mental Health Symptom Detection Dataset and Model. (<i>EMNLP'22</i>)</li>
		<li><a href="https://aclanthology.org/2023.emnlp-main.562.pdf">PsyEx</a>: Detection of Multiple Mental Disorders from Social Media with Two-Stream Psychiatric Experts. (<i>EMNLP'23</i>)</li>
		<li><a href="https://arxiv.org/abs/2311.09189">PsyEval</a>: A Comprehensive Large Language Model Evaluation Benchmark for Mental Health</li>
		<li><a href="https://arxiv.org/abs/2305.13614">PsyDial</a>: LLM-empowered chatbots for psychiatrist and patient simulation: application and evaluation</li>
		<li><a href="https://aclanthology.org/2022.emnlp-main.156.pdf">D4</a>: A Chinese Dialogue Dataset for Depression-Diagnosis-Oriented Chat (<i>EMNLP'22</i>) - we built a system supporting spoken dialogue for depression diagnosis on this!</li>
	</article>
    <!-- Replicate the above Div block to add more title and company details --> 
  </section>
	<section class="section2">
    <h2 class="sectionTitle">Publications. </h2>
    <hr class="sectionTitleRule3">
	<p class="sectionContent"><strong>Selected Papers. Full list please see my <a href="https://scholar.google.com/citations?user=9cvRM5wAAAAJ&hl=en">Google Scholar</a> </strong></p>
	<ol class="sectionContent">
        <li>Siyu Lou, Xuenan Xu, <strong>Mengyue Wu</strong> and Kai Yu. Audio-Text Retrieval in Context. <i>ICASSP'22</i>, <a href="AboutPageAssets/papers/syl92-lou-icassp22.pdf">syl92-lou-icassp22.pdf</a></li>
        <li>Xuenan Xu, <strong>Mengyue Wu</strong> and Kai Yu. Diversity-controllable and Accurate Audio Captioning Based on Neural Condition. <i>ICASSP'22</i>, <a href="AboutPageAssets/papers/xnx98-xu-icassp22.pdf">xnx98-xu-icassp22.pdf</a></li>
        <li>Wen Wu, <strong>Mengyue Wu</strong> and Kai Yu. Climate and Weather: Inspecting Depression Detection via Emotion Recognition. <i>ICASSP'22</i>, <a href="AboutPageAssets/papers/myw19-wu-icassp22-1.pdf">myw19-wu-icassp22-1.pdf</a></li>
        <li>Zhiling Zhang, Siyuan Chen, <strong>Mengyue Wu</strong>, Kenny Zhu. Psychiatric Scale Guided Risky Post Screening for Early Detection of Depression. <i>IJCAI'22</i>, <a href="AboutPageAssets/papers/syc20-chen-ijcai22.pdf">syc20-chen-ijcai22.pdf</a></li>
        <li>Pingyue Zhang, <strong>Mengyue Wu</strong>, Heinrich Dinkel and Kai Yu. DEPA: Self-Supervised Audio Embedding for Depression Detection. <i>ACM-MM'21</i>, <a href="AboutPageAssets/papers/myw19-wu-mm2021.pdf">myw19-wu-mm2021.pdf</a></li>
        <li>Heinrich Dinkel, <strong>Mengyue Wu</strong> and Kai Yu. Towards Duration Robust Weakly Supervised Sound Event Detection. <i>IEEE&#x2F;ACM Transactions on Audio, Speech, and Language Processing, 2021</i>, <a href="AboutPageAssets/papers/hedi7-dinkel-taslp2021.pdf">hedi7-dinkel-taslp2021.pdf</a></li>
	<li><strong>Mengyue Wu</strong>, Heinrich Dinkel and Kai Yu. Audio Caption: Listen and Tell. <i>ICASSP'19</i>, <a href="AboutPageAssets/papers/myw19-wu-icassp2019.pdf">myw19-wu-icassp2019.pdf</a></li>
	</ol>
  </section>
<section class="section2">
    <h2 class="sectionTitle">Teaching</h2>
    <hr class="sectionTitleRule">
    <hr class="sectionTitleRule2">
    <!-- First Title & company details  -->
    <article class="section2Content">
	  <p class="sectionContent"> AI3611 Deep Learning: A Practical Course on Perception and Cognition</p>
	  <p class="sectionContent"> CS3309 Computer Ethics - A newly-designed course covering AI ethics, fairness, bias, etc.</p>
	  <p class="sectionContent"> GE6001 Scientific Writing, Integrity and Ethics - A compulsory course for graduate students, I renovated the course and basically talked about how academia works. Comment from students:"<em>thought would be boring, but turned out super practical and fun</em>"</p>
    </article>

	<section class="section2">
    <h2 class="sectionTitle">Students(Booming in progress)</h2>
    <hr class="sectionTitleRule">
    <hr class="sectionTitleRule2">
    <!-- First Title & company details  -->

    <article class="section2Content">
    <p class="sectionContent"><strong>Current Students</strong> </p>
	  <p class="sectionContent"><a href="https://scholar.google.com/citations?user=e0h0ae8AAAAJ&hl=zh-CN">Xuenan Xu</a>, PhD Candidate, graduate in 2025. Audio understanding and generation.</p>
	  <p class="sectionContent">Kunyao Lan, PhD Candidate. Digital mental health. </p>
	  <p class="sectionContent">Xiujie Song, Co-advised PhD Candidate. Cognitive function evaluation and its application in LLM. </p> 
	  <p class="sectionContent">Jiaming Luo, Co-advised PhD Candidate. Multimodal imagination. </p> 
	  <p class="sectionContent"><a href="https://scholar.google.com/citations?user=LzSAnHMAAAAJ&hl=zh-CN">Zeyu Xie</a>, Master Candidate, graduate in 2025. Audio generation. </p>
	  <p class="sectionContent"><a href="https://scholar.google.com/citations?user=SPngdHIAAAAJ&hl=en">Siyuan Chen</a>, Master Candidate. Digital mental health.</p>
	  <p class="sectionContent">Fei Yang, Master Candidate. Pathological speech detection. </p>
	  <p class="sectionContent">Xiaohang Xu, Master Candidate. Emotion speech analysis and generation. </p>
	  <p class="sectionContent">Minghao Lv, Master Candidate. Causal relations. </p>
	  <p class="sectionContent">Haoan Jin, Master Candidate. Mental and ancient Chinese decoding. </p>
	  <p class="sectionContent">Hao Tang, Master Candidate. Agents and so on. </p>
	  <p class="sectionContent">Xingyuan Li, Master Candidate. Animal language decoding. </p>
	  <p class="sectionContent">Chunhao Zhang, Master Candidate. Cognitive reasoning. </p>
	  <p class="sectionContent">Yufei Wang, Master Candidate. Multimodal emotion recognition. </p>
	  <p class="sectionContent">Zhige Huang, Master Candidate. Ancient language decoding. </p>
	  <p class="sectionContent">Jiaxi Liu, Master Candidate to be. Pathological speech. </p>
	  <p class="sectionContent">Baihan Li, Master Candidate to be. Audio generation. </p>
	 <p class="sectionContent"><strong>Alumni</strong> </p>
	  <p class="sectionContent"><a href="https://www.xing.com/profile/Heinrich_Dinkel">Heinrick Dinkel</a>, Co-advised PhD, 2020. Senior Algorithm Researcher at Xiaomi</p>
	  <p class="sectionContent"><a href="https://bigbinnie.github.io/">Binwei Yao</a>, B.Eng, 2022. Current PhD candidate at the Univeristy of Wisconsin-Madison.</p>
	  <p class="sectionContent">Guangwei Li, Master, 2023. Algorithm researcher at Ant Group. </p>
	  <p class="sectionContent">Pingyue Zhang, Master, 2024. Pursue PhD overseas.</p>
	  <p class="sectionContent">Dengdeng Huang, B.Eng, 2024. PhD at SJTU.</p>
    </article>
<footer>
  <hr>
  <p class="footerDisclaimer">2022  Copyrights - <span>All Rights Reserved</span></p>
  <p class="footerNote">Mengyue Wu - <span>Email me</span></p>
</footer>
</body>
</html>
